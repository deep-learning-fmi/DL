
# Lectures

### [Lecture 1](./Lectures/Lecture1.pptx)
 
> Introduction to Deep Learning

### [Lecture 2](./Lectures/Lecture2.pptx)

> Neural Networks
>
> Backpropagation
>
> Modular Design
>
> [Code](./Lectures/code-l2.zip)

### [Lecture 3](./Lectures/Lecture3.pptx)

> Convolutional Neural Networks

### [Lecture 4](./Lectures/Lecture4.pptx)

> Regularization
>
> Transfer Learning
>
> Data Augmentation

### [Lecture 5](./Lectures/Lecture5.pptx)

> Recurrent Neural Networks
>
> Long Short-Term Memory
>
> Sequence-to-sequence

### [Lecture 6](./Lectures/Lecture6.pptx)

> Auto-encoders
>
> Convolutional Auto-encoders
>
> Denoising Auto-encoders
>
> Contractive Auto-encoders
>
> Stacked Auto-encoders
>
> Applications

### [Lecture 7](./Lectures/Lecture7.pptx)

> Generative Adversarial Networks
>
> Cycle-consistent Generative Adversarial Networks

### [Lecture 8](./Lectures/Lecture8.pptx)

> Object Localization
>
> Object Detection
>
> Faster R-CNN
>
> YOLO

### [Lecture 9](./Lectures/Lecture9.pptx)

> Curriculum Learning
>
> Object Localization and Detection
>
> Image Generation

### [Lecture 10](./Lectures/Lecture10.pptx)

> Distributional Semantics
>
> Word Embeddings
>
> Skip-gram Model
>
> Continuous Bag-of-Words Model

### [Lecture 11](./Lectures/Lecture11.pptx)

> Lessons Learned from Word Embeddings
>
> Document Embeddings

### [Lecture 12](./Lectures/Lecture12.pptx)

> Multi-Head Self-Attention
>
> Language Transformers
>
> Vision Transformers

### [Lecture 13](./Lectures/Lecture13.pptx)

> Adversarial Examples
>
> Robustness to Adversarial Examples

# Labs 

### [Lab1](./Labs/Lab1.zip)

> Introduction to Tensorflow
>
> CNNs for Image Classification
>
> [MNIST Dataset](./Labs/mnist.zip)
>
> [Solution](./Labs/Lab1-Solution.zip)

### [Lab2](./Labs/Lab2.zip)

> CNNs for Text Classification
>
> [Solution](./Labs/Lab2-Solution.zip)

### [Lab3](./Labs/Lab3.zip)

> Transfer Learning
>
> [Solution](./Labs/Lab3-Solution.zip)
>
> If possible, please download in advance the Caltech 101 dataset from this [url](https://drive.google.com/file/d/137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp/view)

### [Lab4](./Labs/Lab4.zip)

> Long Short-Term Memory networks (LSTM)
>
> [Solution](./Labs/Lab4-Solution.zip)

### [Lab5](./Labs/Lab5.zip)

> Autoencoders and Variational Autoencoders
>
> [Solution](./Labs/Lab5-Solution.zip)

### [Lab6](./Labs/Lab6.zip)

> Generative Adversarial Networks
>
> [Solution](./Labs/Lab6-Solution.zip)

### [Lab7](./Labs/Lab7.zip)

> Language Transformers


# Projects (overdue 2)

### Compare Deep Models on Individual Data Set

> Students are required to propose a unique data set and three deep learning methods (to the lab assistants).
>
> [Link to chosen data sets and methods](https://docs.google.com/spreadsheets/d/1RBWBxaQqEv4r8ZkUVt_8rfAl0BhHpAVB2dMVF3l7904/edit?usp=sharing)

### Timeline

> Choice deadline: August 20th, 2022
>
> Submission deadline: August 30th, 2022
>
> Presentation deadline: September 2nd, 2022

# Projects 

### Vision Task on Kaggle

> [Link to challenge](https://www.kaggle.com/c/dl-2020-unibuc-cv/)

### NLP Task on Kaggle

> [Link to challenge](https://www.kaggle.com/c/dl-2020-unibuc-nlp)

# Projects 

### Task on Kaggle

> [Link to challenge](https://www.kaggle.com/c/detect-targets-in-radar-signals/)
>
> To join the competition, you must join the team on MS Teams.

# Projects (overdue)

### Compare Deep Models on Individual Data Set

> Students are required to propose a unique data set and three deep learning methods (to the lab assistants).
>
> [Link to chosen data sets and methods](https://docs.google.com/spreadsheets/d/1RBWBxaQqEv4r8ZkUVt_8rfAl0BhHpAVB2dMVF3l7904/edit?usp=sharing)

### Timeline

> Choice deadline: April 13th, 2022
>
> Submission deadline: April 27th, 2022
>
> Presentation deadline: May 4th, 2022
